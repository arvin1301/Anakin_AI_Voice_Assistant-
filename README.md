# Anakin_AI_Voice_Assistant-

# ğŸ¤ Anakin â€“ Real-Time AI Voice Assistant

Anakin is a **real-time AI voice assistant** built using:

-  **Groq Llama-3.1-8B-instant** (via OpenAI-compatible API)  
-  **SpeechRecognition** (Google Web Speech API) for Speech-to-Text  
-  **pyttsx3** for offline Text-to-Speech  
-  **Open-Meteo API** for live weather  
-  **Wikipedia API** for knowledge lookup  
-  **Google search** integration  
-  Voice-driven **notes** and **reminders**  
-  **OpenCV** for webcam photo capture  
-  **Streamlit** for a browser-based UI  

This project was developed as a **Data Science internship project at Inlighn Tech** by **Arvind Sharma**.

---

##  Features

-  **Continuous voice listening** (console + Streamlit)
-  **Speech-to-Text (STT)** using `speech_recognition` + Google STT  
-  **Text-to-Speech (TTS)** with `pyttsx3`  
  - Global **mute/unmute** control (`VOICE_ENABLED`)  
-  **Groq Llama-3.1-8B-instant** for general Q&A and chat
-  **Weather queries** using Open-Meteo  
  - Robust **geocoding with fallback** (handles â€œBangaloreâ€, â€œKarnatakaâ€, â€œBangalore Karnatakaâ€)  
-  **Wikipedia summaries** â€“ Short 2-sentence topic explanations  
-  **Google Search integration**  
  - Commands like `search google for ...` or `google <query>` open a browser  
-  **Notes** â€“ â€œwrite a noteâ€, stored in `notes.txt` with timestamps  
-  **Reminders** â€“ â€œset a reminderâ€, stored in `reminders.txt` with timestamps  
-  **Photo capture** â€“ â€œtake a photoâ€ saves webcam images in `photos/`  
-  **Time & Date** queries  
-  **Streamlit UI** for:
  - Start/Stop Listening  
  - Conversation history  

---

##  Tech Stack

- **Language:** Python 3.10+
- **Core Libraries:**
  - `speechrecognition`
  - `pyttsx3`
  - `pyaudio`
  - `requests`
  - `wikipedia`
  - `python-dotenv`
  - `openai` (Groq-compatible client)
  - `opencv-python`
  - `streamlit`
- **External APIs:**
  - [Groq API](https://groq.com) â€“ Llama-3.1-8B-instant  
  - [Open-Meteo](https://open-meteo.com/) â€“ Weather & Geocoding  
  - [Wikipedia](https://pypi.org/project/wikipedia/) â€“ Summaries  
  - Google Search (via `webbrowser` module)

---

##  Project Structure

```bash
anakin-voice-assistant/
â”œâ”€ main.py                  # Core console-based voice assistant
â”œâ”€ app.py                   # Streamlit web UI (continuous listening)
â”œâ”€ requirements.txt         # Python dependencies
â”œâ”€ .env.example             # Example environment variables
â”œâ”€ README.md                # Project documentation
â”œâ”€ LICENSE                  # License (MIT suggested)
â”œâ”€ docs/
â”‚  â””â”€ Anakin_Voice_Assistant_Research_Documentation.pdf
â”œâ”€ photos/                  # Auto-created: saved webcam photos
â”œâ”€ notes.txt                # Auto-created: text notes
â”œâ”€ reminders.txt            # Auto-created: reminders
â””â”€ .gitignore               # Ignore venv, __pycache__, etc.
âš™ï¸ Installation
1ï¸âƒ£ Clone the repository
bash
Copy code
git clone https://github.com/<your-username>/anakin-voice-assistant.git
cd anakin-voice-assistant
2ï¸âƒ£ Create & activate a virtual environment (recommended)
Windows (PowerShell):

bash
Copy code
python -m venv venv
venv\Scripts\activate
Linux / macOS:

bash
Copy code
python3 -m venv venv
source venv/bin/activate
3ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
4ï¸âƒ£ Configure environment variables
Create a .env file in the project root (next to main.py) based on .env.example:

env
Copy code
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant
Get your Groq API key from your Groq account.

The default model in this project is llama-3.1-8b-instant.

â–¶ï¸ Usage
You can run Anakin in two modes:

A. Console Mode (Terminal / PyCharm)
bash
Copy code
python main.py
Workflow:

Anakin introduces itself.

Youâ€™ll see messages like:

Listening...

Recognizing...

Speak commands like:

â€œWhat is the weather in Bangalore?â€

â€œWikipedia machine learningâ€

â€œSearch Google for YOLOv10 tutorialsâ€

â€œWrite a note. I have a meeting tomorrow at 5 PM.â€

â€œSet a reminder. Call mentor at 8 PM.â€

â€œTake a photoâ€

â€œExplain overfitting in simple termsâ€

Say exit, quit, or bye to stop Anakin.

Voice control:

Say â€œstop Anakinâ€ or â€œmute Anakinâ€ â†’ TTS is muted (text only).

Say â€œstart Anakinâ€, â€œAnakin speakâ€, or â€œunmuteâ€ â†’ TTS is enabled again.

B. Web UI Mode (Streamlit)
bash
Copy code
streamlit run app.py
This will:

Open a browser tab (usually at http://localhost:8501)

Show:

 Anakin Voice Assistant â€“ Continuous Listening

Buttons:

 Start Listening

 Stop Listening

Conversation history

How it works:

Click Start Listening

Speak your commands (same as console mode)

The assistant will:

Transcribe your speech

Process the command

Speak and display the response

Click Stop Listening or say exit / quit / bye to stop.

 Supported Voice Commands
Some example phrases you can use:

ğŸ”¹ Time & Date
â€œWhat is the time?â€

â€œWhat is todayâ€™s date?â€

â€œTell me the date todayâ€

ğŸ”¹ Weather
â€œWhat is the weather in Bangalore?â€

â€œTell me the weather in Karnatakaâ€

â€œWeather in New Delhiâ€

ğŸ”¹ Wikipedia
â€œWikipedia machine learningâ€

â€œWiki neural networksâ€

â€œWikipedia Elon Muskâ€

ğŸ”¹ Google Search
â€œSearch Google for object detection using YOLOv10â€

â€œGoogle latest AI newsâ€

â€œGoogle Python decoratorsâ€

ğŸ”¹ Notes & Reminders
â€œWrite a note. I have a project review tomorrow.â€

â€œTake a note. Buy groceries today.â€

â€œSet a reminder. Call my friend at 6 PM.â€

â€œRemind me to submit my assignment.â€

ğŸ”¹ Camera
â€œTake a photoâ€

â€œClick a photoâ€

â€œTake a pictureâ€

ğŸ”¹ General Questions (LLM)
â€œExplain overfitting in simple terms.â€

â€œWhat is the difference between supervised and unsupervised learning?â€

â€œHelp me understand gradient descent.â€

 Architecture Overview
Pipeline (high-level):

text
Copy code
User Speech
     â†“
SpeechRecognition (Google STT)
     â†“
Recognized Text (lowercased)
     â†“
Intent Recognition / Command Engine
     â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 | Predefined Commands           |   General Query (fallback)   |
 | (weather, wiki, google, etc.) | â†’ Groq Llama-3.1-8B-instant  |
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
Action or AI Response
     â†“
Text-to-Speech (pyttsx3) + UI Output (Streamlit / Console)
 Research Documentation
Full research-style project report is available in:

bash
Copy code
docs/Anakin_Voice_Assistant_Research_Documentation.pdf
It includes:

Problem statement

Objectives

Literature review

System design & architecture

Algorithms (STT, TTS, intent recognition, weather, LLM)

Implementation details

Testing & results

Limitations and future work

 Testing
Tested with:

Windows 10

Python 3.10

Conda/venv virtual environments

Typical laptop mic & webcam

Manual test cases include:

Time/date queries

Weather queries (city and state-based)

Wikipedia lookups

Google search commands

Note & reminder creation

Photo capture

General LLM Q&A

Exit, mute, and unmute commands

ğŸ›¡ License
This project is licensed under the MIT License â€“ see the LICENSE file for details.

 Contributing
Contributions are welcome!

Ideas to improve:

Add wake-word detection (â€œHey Anakinâ€)

Add offline STT (Whisper, Vosk)

Add multi-language support

Save conversation history to a database

Add more tools/APIs (YouTube transcripts, WikiHow, Serper, etc.)

Steps:

Fork the repo

Create a new branch: feature/my-awesome-feature

Commit your changes

Push to the branch

Open a Pull Request 

 Author
Arvind Sharma
Data Science Intern â€“ Inlighn Tech

Focus areas: Computer Vision, NLP, LLMs, Time Series

Tools: YOLOv10, DeepSORT, PaddleOCR, Llama, Gemini, Streamlit, Flask

If you use this project or find it helpful, feel free to  the repo and mention it in your portfolio!

yaml
Copy code

---

## 3. `.env.example`

```env
# Copy this file to `.env` and fill your credentials

GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant
4. LICENSE (MIT)
text
Copy code
MIT License

Copyright (c) 2025 Arvind Sharma

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights  
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell  
copies of the Software, and to permit persons to whom the Software is  
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in  
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR  
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,  
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE  
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER  
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,  
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN  
THE SOFTWARE.
5. .gitignore
gitignore
Copy code
# Python
__pycache__/
*.py[cod]
*.pyo
*.pyd
*.log

# Virtual env
venv/
.env

# OS
.DS_Store
Thumbs.db

# Streamlit
.streamlit/

# Photos & runtime files (optional - or keep them tracked if you want)
photos/
notes.txt
reminders.txt
